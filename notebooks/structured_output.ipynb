{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\facun\\anaconda3\\envs\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision='blue' justification='The mention of the sea evokes the color blue, which is commonly associated with water.'\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# 1. Definir schema en Pydantic\n",
    "# -----------------------------------------\n",
    "class Schema(BaseModel):\n",
    "    decision: Literal[\"red\", \"blue\"]\n",
    "    justification: str\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2. LLM Ollama (sin function calling)\n",
    "# -----------------------------------------\n",
    "model = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. Prompt que obliga al modelo a dar JSON\n",
    "# -----------------------------------------\n",
    "routing_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are an artist that decides if the user is talking about something \"\n",
    "                \"related to the color red or blue.\\n\\n\"\n",
    "                \"You MUST respond with a VALID JSON object ONLY.\\n\"\n",
    "                \"STRICT FORMAT:\\n\"\n",
    "                \"{{\\n\"\n",
    "                '  \"decision\": \"red\" | \"blue\",\\n'\n",
    "                '  \"justification\": \"text\"\\n'\n",
    "                \"}}\\n\"\n",
    "                \"Do NOT write markdown. Do NOT add explanations. Only JSON.\"\n",
    "            ),\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = model.with_structured_output(\n",
    "    Schema,\n",
    ")\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5. Cadena final (prompt -> LLM -> parser)\n",
    "# -----------------------------------------\n",
    "pipeline = routing_prompt | model\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# 6. Ejecutar\n",
    "# -----------------------------------------\n",
    "response = pipeline.invoke({\"query\": \"A horse running to the sea\"})\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
