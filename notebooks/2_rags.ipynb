{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019fbabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'text.txt'}, page_content='Hello World !!!')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "path = \"text.txt\"\n",
    "loader = TextLoader(path)\n",
    "documents = loader.load()\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47dec649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.langchain.com/', 'title': 'LangChain', 'description': 'LangChain provides the engineering platform and open source frameworks developers use to build, test, and deploy reliable AI agents.', 'language': 'en'}, page_content=\"LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProducts\\n\\nOpen Source FrameworksLangChainQuick start agents with any model providerLangGraphBuild custom agents with low-level controlDeep AgentsNewUse planning, memory, and sub-agents for complex, long-running tasksLangSmithObservabilityDebug and monitor in-depth tracesEvaluationIterate on prompts and modelsDeploymentShip and scale agents in productionResources\\n\\nLangChain AcademyBlogCustomer StoriesCommunityEventsChangelogGuidesTrust CenterDocsCompany\\n\\nAboutCareersPricingGet a demoSign upEngineer reliable agentsShip agents to production with LangChain's comprehensive platform for agent engineering.Request a demoSign up\\n\\nWe've raised a $125M\\xa0Series B to build the platform for agent engineering.Read more\\n\\n\\nLangChain products power top engineering teams, from AI startups to global enterprisesVisibility &\\xa0controlSee exactly what's happening at every step of your agent. Steer your agent to accomplish critical tasks the way you intended.Fast iterationRapidly move through build, test, deploy, learn, repeat with workflows across the entire agent engineering lifecycle.Durable performanceShip at scale with agent infrastructure designed for long-running workloads and human oversight.Model neutralSwap models, tools, and databases without rewriting your app. Future-proof your stack as AI advances with no vendor lock-in.Your agent engineering stackOpen Source FrameworksLangChainLangChain helps you ship quickly with less code using a pre-built agent architecture and model integrations.LangGraphLangGraph puts you in control with low-level primitives to build custom agent workflows.Agent Engineering PlatformLangSmithObservabilityEvaluationDeploymentObservabilityEvaluationDeploymentSee exactly what your agent is doingAgents create dense outputs that make debugging hard. Tracing gives you clear visibility into each step, so you can quickly identify issues and confidently explain what your agent is actually doing.LangSmith Observability\\n\\n\\nImprove agent quality with evalsLLMs are non-deterministic and output natural language, making responses hard to evaluate for accuracy and quality. Build realistic test sets from production data, score performance with evaluators and expert feedback, and iterate to get your agent from 'okay' to 'great'.LangSmith Evaluation\\n\\n\\nDeploy with infrastructure built for agentsStandard infrastructure can’t handle long-running agent workloads that need human collaboration. Deploy in one click with APIs that handle memory, auto-scaling, and enterprise-grade security out of\\xa0the box — built for agent workflows that run for hours or days.LangSmith Deployment\\n\\n\\nBuild agents your way, with templates or custom controlBring your own frameworkLangSmith is framework-agnostic. Trace using the TypeScript or Python SDK\\xa0to gain visibility into your agent interactions, whether you use LangChain's frameworks or not.Open Source Frameworks\\xa0Bring your ownAgent Engineering PlatformLangSmithObservabilityEvaluationDeploymentYour agent engineering stackOpen Source FrameworksBuild agents your way, with templates or custom controlLangChain helps you ship quickly with less code using a pre-built agent architecture and model integrations.LangGraph puts you in control with low-level primitives to build custom agent workflows.LangSmith Agent Engineering PlatformSee exactly what your agent is doingAgents create dense outputs that make debugging hard. Tracing gives you clear visibility into each step, so you can quickly identify issues and confidently explain what your agent is actually doing.LangSmith Observability\\n\\n\\nLangSmith Agent Engineering PlatformImprove agent quality with evalsLLMs are non-deterministic and output natural language, making responses hard to evaluate for accuracy and quality. Build realistic test sets from production data, score performance with evaluators and expert feedback, and iterate to get your agent from 'okay' to 'great'.LangSmith Evaluation\\n\\n\\nLangSmith Agent Engineering PlatformDeploy with infrastructure built for agentsStandard infrastructure can’t handle long-running agent workloads that need human collaboration. Deploy in one click with APIs that handle memory, auto-scaling, and enterprise-grade security out of\\xa0the box — built for agent workflows that run for hours or days.LangSmith Deployment\\n\\n\\nExplore top agent use casesCopilotsBuild native co-pilots into your application to unlock new end user experiences for domain-specific tasks.Enterprise GPTGive all employees access to information and tools in a compliant manner so they can perform their best.Customer SupportImprove the speed and efficiency of support teams that handle customer requests.ResearchSynthesize data, summarize sources, and uncover insights faster for knowledge work.Code generationAccelerate software development by automating code writing, refactoring, and documentation for your team.AI SearchOffer a concierge experience to guide users to products or information in a personalized way.\\n\\n\\n\\n\\n\\nGet inspired by companies who have done itTeams building with LangChain products are driving operational efficiency, increasing discovery & personalization, and delivering premium products that generate revenue.Read their stories\\n\\n\\nFinancial ServicesKlarna's AI assistant reduced customer query resolution time by 80%, powered by LangSmith and LangGraph.\\n\\n\\nB2B SaaSElastic’s AI security assistant, built with LangSmith and LangGraph, cut alert response times for 20,000+ customers.\\n\\n\\nAI/MLReplit's AI Agent serves 30+ million developers. Their AI engineers rely on LangSmith to debug complex traces.\\n\\n\\nLearn alongside the 1 million+ practitioners who are pushing the industry forward90MMonthly downloads100k+GitHub stars#1Downloaded agent framework1000IntegrationsReady to start shipping \\u2028reliable agents faster?Get started with tools from the LangChain product suite for every step of the agent development lifecycle.Get a demoSign up for freeProductsLangChainLangGraphLangSmith ObservabilityLangSmith EvaluationLangSmith DeploymentResourcesGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogDocsCompanyAboutCareersXLinkedInYouTubeMarketing AssetsSecuritySign up for our newsletter to stay up to dateThank you! Your submission has been received!Oops! Something went wrong while submitting the form.All systems operationalPrivacy PolicyTerms of Service\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url = \"https://www.langchain.com/\"\n",
    "\n",
    "loader = WebBaseLoader(url)\n",
    "pages = loader.load()\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86f11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': '', 'creator': '', 'creationdate': 'D:20200416', 'title': '', 'author': '', 'subject': '', 'source': 'historia_academica_16-04-2020.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Fecha Actividad Tipo Nota Resultado\\nHISTORIA ACADÉMICA\\nPropuesta: Licenciatura en Ciencias Matemáticas\\nAlumno: Facundo Ernesto Serna\\n1 de 1 16/04/2020 16:57:17\\n20/10/2016 Álgebra I (MATE820001) Examen 6 Aprobado\\n25/04/2017 Análisis I (MATE820007)Examen 6 Aprobado\\n20/09/2017 Análisis II (MATE820008)Examen 8 Aprobado\\n19/06/2019 Álgebra Lineal (MATE820004)Examen 8 Aprobado\\n26/02/2020 Cálculo Avanzado (MATE820011)Examen 10 Aprobado')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "path = \"Game Theory Alive.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "pages = loader.load()\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "path = \"Game Theory Alive.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91e737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Parte I\n",
      "Espacios Muestrales Finitos\n",
      "Pablo L. De N´ apoli (DM- UBA ) El Espacio Muestral clase 1 2 / 39' metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with Beamer class', 'creationdate': '2021-10-02T22:33:03-03:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2021-10-02T22:33:03-03:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020/Debian) kpathsea version 6.3.2', 'source': 'clase-02-espacio_muestral.pdf', 'total_pages': 39, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f6c770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(Language.PYTHON, chunk_size=50, chunk_overlap=0)\n",
    "python_chunks = python_splitter.create_documents([PYTHON_CODE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c6a2bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(metadata={}, page_content='# Call the function\\nhello_world()')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbff9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "model = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "vector = model.embed_query(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3109907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.embed_documents([\n",
    "    \"Hello World\",\n",
    "    \"Oh Hello there\",\n",
    "    \"What's your name?\",\n",
    "    \"My friends call me LangChain\",\n",
    "    \"hi there\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a42b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "path = \"Game Theory Alive.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "model = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "embeddings = model.embed_documents([doc.page_content for doc in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ea48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393\n"
     ]
    }
   ],
   "source": [
    "#docker run --name pgvector-container -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16\n",
    "\n",
    "#postgresql+psycopg://langchain:langchain@localhost:6024/langchain\n",
    "\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "path = \"Game Theory Alive.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "print(len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents,\n",
    "    embeddings_model,\n",
    "    connection=connection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07d11efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_documents = db.similarity_search(\"Convex\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd519eb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'most_similar_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmost_similar_documents\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content\n",
      "\u001b[1;31mNameError\u001b[0m: name 'most_similar_documents' is not defined"
     ]
    }
   ],
   "source": [
    "most_similar_documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09993704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "path = \"gnomas_2.txt\"\n",
    "loader = TextLoader(path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e428091",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c72bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/gnomas\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents,\n",
    "    embeddings_model,\n",
    "    connection=connection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6ed8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_documents = db.similarity_search(\"Guardian\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72c8b366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. LOS GIGANTONES GUARDIANES\n",
      "Los Gigantones son criaturas colosales, de entre 2 y 3 metros de altura, creadas por las gnomas como protectores del Bosquecillo. Nacen de un ritual ancestral que combina savia, piedra y canto armónico.\n",
      "--------------------------\n",
      "Sociedad: Comunidades cooperativas llamadas Bosquecillos\n",
      "Guardianes: Gigantones (criaturas de piedra y savia)\n",
      "Gobierno central: Asociación GNOM\n",
      "Valores: Equilibrio, cooperación, armonía ecológica\n",
      "Espiritualidad: La Vibración del Todo\n",
      "Símbolo vital: Marca luminosa en la frente\n",
      "--------------------------\n",
      "1. DESCRIPCIÓN GENERAL\n",
      "--------------------------\n",
      "Los Gigantones no son considerados armas, sino manifestaciones del equilibrio natural: un recordatorio viviente del pacto entre piedra y raíz.\n",
      "--------------------------\n",
      "8. RESUMEN GENERAL\n",
      "Especie: Gnomas\n",
      "Altura: 20–35 cm\n",
      "Esperanza de vida: Hasta 200 años\n",
      "Habilidades: Bioarquitectura, camuflaje dinámico, memoria de enjambre, empatía, energía gnómica\n",
      "Sociedad: Comunidades cooperativas llamadas Bosquecillos\n",
      "Guardianes: Gigantones (criaturas de piedra y savia)\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for doc in most_similar_documents:\n",
    "    print(doc.page_content)\n",
    "    print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d582c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45007d31",
   "metadata": {},
   "source": [
    "# Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40affdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/gnomas\"\n",
    "\n",
    "db = PGVector(\n",
    "    embeddings=embeddings_model,\n",
    "    connection=connection,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a8c2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "\n",
    "docs = retriever.invoke(\"\"\"Cuál es la historia de los gnomos guardianes?\"\"\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f0740c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='f9f8b000-ab59-4765-a927-8ccd4d9015ed', metadata={'source': 'gnomas_2.txt'}, page_content='4. LOS GIGANTONES GUARDIANES\\nLos Gigantones son criaturas colosales, de entre 2 y 3 metros de altura, creadas por las gnomas como protectores del Bosquecillo. Nacen de un ritual ancestral que combina savia, piedra y canto armónico.'),\n",
       " Document(id='aad331ca-3e7e-4fa6-92a2-0af24f7f174e', metadata={'source': 'gnomas_2.txt'}, page_content='5. GOBIERNO CENTRAL: LA ASOCIACIÓN GNOM\\nLa Asociación GNOM (Gran Nexo de Orden y Memoria) es la red que conecta todos los Bosquecillos del mundo gnómico. Su sede está ubicada en el mítico Árbol de los Ecos, una estructura viva que se cree tiene más de mil años y cuya savia brilla como la aurora.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Contesta la pregunta basandote únicamente en el siguiente contexto:\n",
    "        {context}\n",
    "    Pregunta: {question}\n",
    "    \"\"\")\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "question = \"Cuál es la historia de los gnomos guardianes?\"\n",
    "docs = retriever.invoke(question, k=2)\n",
    "\n",
    "response = chain.invoke({\"context\": \"\\n\\n\".join([doc.page_content for doc in docs]),\n",
    "                         \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8f5cc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los gnomos guardianes, conocidos como **Gigantones**, surgieron cuando las propias gnomas, deseando proteger sus Bosquecillos, realizaron un antiguo ritual que combina tres elementos esenciales de su cultura: **savia**, **piedra** y **canto armónico**. De esa ceremonia nacieron criaturas colosales de entre 2 y 3 metros de altura, diseñadas específicamente para vigilar y defender los bosques.\n",
      "\n",
      "Estos Gigantones forman parte del entramado de la **Asociación GNOM** (Gran Nexo de Orden y Memoria), la red que une a todos los Bosquecillos del mundo gnómico. La sede de la asociación, el mítico **Árbol de los Ecos**, es una estructura viva cuya savia brilla como la aurora y simboliza la continuidad del vínculo entre los gnomos y sus guardianes. Así, la historia de los gnomos guardianes es la de una creación deliberada y sagrada, nacida de la unión de la naturaleza y la música, para salvaguardar el legado y la seguridad de los Bosquecillos bajo la guía de la Asociación GNOM.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ec04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/gnomas\"\n",
    "\n",
    "db = PGVector(\n",
    "    embeddings=embeddings_model,\n",
    "    connection=connection,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "108dd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def qa(question):\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Contesta la pregunta basandote únicamente en el siguiente contexto:\n",
    "        {context}\n",
    "    Pregunta: {question}\n",
    "    \"\"\")\n",
    "\n",
    "    docs = retriever.invoke(question, k=10)\n",
    "\n",
    "    formatted_prompt = prompt.invoke({\n",
    "        \"context\": \"\\n\\n\".join([doc.page_content for doc in docs]),\n",
    "        \"question\": question\n",
    "    })\n",
    "\n",
    "    answer = llm.invoke(formatted_prompt)\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1077d887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Poderes gnómicos (según el contexto proporcionado)**  \n",
      "\n",
      "1. **Sello vital luminoso**  \n",
      "   - Cada gnoma lleva en la frente una marca luminosa que varía de brillo según su estado emocional y su nivel de energía gnómica.  \n",
      "   - El sello permite el reconocimiento entre gnomas a distancia, funcionando como una “señal” visual y energética.\n",
      "\n",
      "2. **Desmaterialización parcial**  \n",
      "   - Algunas gnomas pueden convertir parte de su cuerpo en brillos o sombras, mimetizándose con la luz que se filtra entre las hojas.  \n",
      "   - Esta capacidad les otorga camuflaje y movilidad ligera, casi etérea.\n",
      "\n",
      "3. **Canto de energía coral**  \n",
      "   - Las gnomas producen un canto que alimenta a los Gigantones (seres de energía coral).  \n",
      "   - Sin este canto, los Gigantones se inmovilizan y se funden con el paisaje, por lo que el canto es esencial para mantener su vitalidad.\n",
      "\n",
      "4. **Memoria de enjambre**  \n",
      "   - Poseen una red psíquica natural que comparte recuerdos esenciales con todo el Bosquecillo.  \n",
      "   - Cuando una gnoma aprende una técnica o detecta un peligro, esa información se propaga instantáneamente a todas las demás.\n",
      "\n",
      "5. **Sensibilidad al bosque**  \n",
      "   - No piensan como seres racionales, sino que “sienten” el bosque y sus necesidades, lo que les permite actuar en armonía con el entorno y anticipar cambios.\n",
      "\n",
      "6. **Fusión de magia vital y ingenio técnico**  \n",
      "   - Su disciplina central combina la magia de la vida (energía vital, canto, sello luminoso) con habilidades técnicas, lo que les brinda soluciones creativas y efectivas dentro del ecosistema.\n",
      "\n",
      "En conjunto, estos rasgos constituyen los principales **poderes gnómicos** que les permiten comunicarse, protegerse, colaborar con otras criaturas del bosque y mantener el equilibrio del ecosistema consciente.\n"
     ]
    }
   ],
   "source": [
    "answer = qa.invoke(\"Cuáles son los poderes gnómicos?\")\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3544844f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los gnomos son una especie autóctona del bosque consciente que se diferencia de hadas, ninfas o duendes. No adoran dioses, sino procesos naturales como el brote, el fluir y el ciclo, viendo la vida como un pulso continuo de transformación. Cada gnoma lleva en la frente una marca luminosa —el sello vital— cuyo brillo varía según su estado emocional y su nivel de energía gnómica, y que les permite reconocerse a distancia.\n",
      "\n",
      "Son sabias y técnicas: combinan la magia vital con ingenio técnico, y su disciplina central se basa en esa unión. Están organizadas bajo la Asociación GNOM (Gran Nexo de Orden y Memoria), gobernada por las Tres Sabias de Savia, elegidas por su resonancia con la Vibración del Todo; su canto puede restaurar la vida de un bosque entero.\n",
      "\n",
      "Los gnomos crean y guían a los Gigantones, colosales guardianes de 2‑3 m, vinculados a una gnoma “Corazón de Musgo” que actúa como guía y canal emocional. Si una de las dos muere, la otra entra en un sueño pétreo de siglos. Los Gigantones dependen del canto de las gnomas para mantener su vitalidad y solo actúan como defensores pasivos ante amenazas directas al Bosquecillo.\n",
      "\n",
      "Además, poseen la “memoria de enjambre”, una red psíquica que difunde instantáneamente cualquier conocimiento o alerta entre todas las gnomas y el propio Bosquecillo. Algunas pueden desmaterializarse parcialmente, convirtiéndose en brillos o sombras que se confunden con la luz filtrada entre las hojas. En conjunto, los gnomos son seres sabios, conectados a la naturaleza y a una red colectiva que les permite proteger y revitalizar su entorno.\n"
     ]
    }
   ],
   "source": [
    "answer = qa.invoke(\"\"\"\n",
    "                    Hoy tuve un día muy agitado, salí a correr,\n",
    "                    encontré un lapiz tirado en el piso.\n",
    "                    Luego choqué con el auto y cuando lo llevé a reparar me encontraron un quiste.\n",
    "                   Después trabajé 22 horas y luego salí a cenar con amigos.\n",
    "                   Me enteré que mi familia no existía y me volví a casa a dormir en el piso.\n",
    "                   Cómo son los gnomos?\n",
    "                   \"\"\")\n",
    "\n",
    "print(answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
